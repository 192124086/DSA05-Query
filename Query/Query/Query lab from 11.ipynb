{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b3162c-c312-40c9-9065-5e2fda19eaed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_07bb5_row0_col0, #T_07bb5_row0_col1, #T_07bb5_row0_col3, #T_07bb5_row0_col4, #T_07bb5_row1_col0, #T_07bb5_row1_col1, #T_07bb5_row1_col2, #T_07bb5_row1_col3, #T_07bb5_row1_col4, #T_07bb5_row2_col0, #T_07bb5_row2_col1, #T_07bb5_row2_col2, #T_07bb5_row2_col3, #T_07bb5_row2_col4, #T_07bb5_row3_col0, #T_07bb5_row3_col1, #T_07bb5_row3_col2, #T_07bb5_row3_col4, #T_07bb5_row4_col0, #T_07bb5_row4_col2, #T_07bb5_row4_col3, #T_07bb5_row5_col0, #T_07bb5_row5_col1, #T_07bb5_row5_col2, #T_07bb5_row5_col3, #T_07bb5_row5_col4, #T_07bb5_row6_col0, #T_07bb5_row6_col1, #T_07bb5_row6_col2, #T_07bb5_row6_col3, #T_07bb5_row6_col4, #T_07bb5_row7_col0, #T_07bb5_row7_col1, #T_07bb5_row7_col2, #T_07bb5_row7_col3, #T_07bb5_row7_col4, #T_07bb5_row8_col0, #T_07bb5_row8_col1, #T_07bb5_row8_col2, #T_07bb5_row8_col3, #T_07bb5_row8_col4, #T_07bb5_row9_col0, #T_07bb5_row9_col1, #T_07bb5_row9_col2, #T_07bb5_row9_col3 {\n",
       "  color: black;\n",
       "}\n",
       "#T_07bb5_row0_col2, #T_07bb5_row3_col3, #T_07bb5_row4_col1, #T_07bb5_row4_col4, #T_07bb5_row9_col4 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_07bb5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_07bb5_level0_col0\" class=\"col_heading level0 col0\" >A</th>\n",
       "      <th id=\"T_07bb5_level0_col1\" class=\"col_heading level0 col1\" >B</th>\n",
       "      <th id=\"T_07bb5_level0_col2\" class=\"col_heading level0 col2\" >C</th>\n",
       "      <th id=\"T_07bb5_level0_col3\" class=\"col_heading level0 col3\" >D</th>\n",
       "      <th id=\"T_07bb5_level0_col4\" class=\"col_heading level0 col4\" >E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_07bb5_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_07bb5_row0_col1\" class=\"data row0 col1\" >1.329210</td>\n",
       "      <td id=\"T_07bb5_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_07bb5_row0_col3\" class=\"data row0 col3\" >-0.316280</td>\n",
       "      <td id=\"T_07bb5_row0_col4\" class=\"data row0 col4\" >-0.990810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_07bb5_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_07bb5_row1_col1\" class=\"data row1 col1\" >-1.070820</td>\n",
       "      <td id=\"T_07bb5_row1_col2\" class=\"data row1 col2\" >-1.438710</td>\n",
       "      <td id=\"T_07bb5_row1_col3\" class=\"data row1 col3\" >0.564417</td>\n",
       "      <td id=\"T_07bb5_row1_col4\" class=\"data row1 col4\" >0.295722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_07bb5_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_07bb5_row2_col1\" class=\"data row2 col1\" >-1.626400</td>\n",
       "      <td id=\"T_07bb5_row2_col2\" class=\"data row2 col2\" >0.219565</td>\n",
       "      <td id=\"T_07bb5_row2_col3\" class=\"data row2 col3\" >0.678805</td>\n",
       "      <td id=\"T_07bb5_row2_col4\" class=\"data row2 col4\" >1.889270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_07bb5_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_07bb5_row3_col1\" class=\"data row3 col1\" >0.961538</td>\n",
       "      <td id=\"T_07bb5_row3_col2\" class=\"data row3 col2\" >0.104011</td>\n",
       "      <td id=\"T_07bb5_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_07bb5_row3_col4\" class=\"data row3 col4\" >0.850229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_07bb5_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_07bb5_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "      <td id=\"T_07bb5_row4_col2\" class=\"data row4 col2\" >1.057740</td>\n",
       "      <td id=\"T_07bb5_row4_col3\" class=\"data row4 col3\" >0.165562</td>\n",
       "      <td id=\"T_07bb5_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_07bb5_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_07bb5_row5_col1\" class=\"data row5 col1\" >-1.336940</td>\n",
       "      <td id=\"T_07bb5_row5_col2\" class=\"data row5 col2\" >0.562861</td>\n",
       "      <td id=\"T_07bb5_row5_col3\" class=\"data row5 col3\" >1.392850</td>\n",
       "      <td id=\"T_07bb5_row5_col4\" class=\"data row5 col4\" >-0.063328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_07bb5_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_07bb5_row6_col1\" class=\"data row6 col1\" >0.121668</td>\n",
       "      <td id=\"T_07bb5_row6_col2\" class=\"data row6 col2\" >1.207600</td>\n",
       "      <td id=\"T_07bb5_row6_col3\" class=\"data row6 col3\" >-0.002040</td>\n",
       "      <td id=\"T_07bb5_row6_col4\" class=\"data row6 col4\" >1.627800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_07bb5_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_07bb5_row7_col1\" class=\"data row7 col1\" >0.354493</td>\n",
       "      <td id=\"T_07bb5_row7_col2\" class=\"data row7 col2\" >1.037530</td>\n",
       "      <td id=\"T_07bb5_row7_col3\" class=\"data row7 col3\" >-0.385684</td>\n",
       "      <td id=\"T_07bb5_row7_col4\" class=\"data row7 col4\" >0.519818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_07bb5_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_07bb5_row8_col1\" class=\"data row8 col1\" >1.686580</td>\n",
       "      <td id=\"T_07bb5_row8_col2\" class=\"data row8 col2\" >-1.325960</td>\n",
       "      <td id=\"T_07bb5_row8_col3\" class=\"data row8 col3\" >1.428980</td>\n",
       "      <td id=\"T_07bb5_row8_col4\" class=\"data row8 col4\" >-2.089350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07bb5_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_07bb5_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_07bb5_row9_col1\" class=\"data row9 col1\" >-0.129820</td>\n",
       "      <td id=\"T_07bb5_row9_col2\" class=\"data row9 col2\" >0.631523</td>\n",
       "      <td id=\"T_07bb5_row9_col3\" class=\"data row9 col3\" >-0.586538</td>\n",
       "      <td id=\"T_07bb5_row9_col4\" class=\"data row9 col4\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e167375810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(24)\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [1.32921, -1.07082, -1.6264, 0.961538, np.nan, -1.33694, 0.121668, 0.354493, 1.68658, -0.12982],\n",
    "    'C': [np.nan, -1.43871, 0.219565, 0.104011, 1.05774, 0.562861, 1.2076, 1.03753, -1.32596, 0.631523],\n",
    "    'D': [-0.31628, 0.564417, 0.678805, np.nan, 0.165562, 1.39285, -0.00204021, -0.385684, 1.42898, -0.586538],\n",
    "    'E': [-0.99081, 0.295722, 1.88927, 0.850229, np.nan, -0.063328, 1.6278, 0.519818, -2.08935, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "def color_negative_red(val):\n",
    "    color = 'red' if pd.isnull(val) else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "styled_df = df.style.applymap(color_negative_red)\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68481df8-ec4e-4e3b-a144-28b2d1807b82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "    A         B         C         D         E\n",
      "0   1  1.329210       NaN -0.316280 -0.990810\n",
      "1   2 -1.070820 -1.438710  0.564417  0.295722\n",
      "2   3 -1.626400  0.219565  0.678805  1.889270\n",
      "3   4  0.961538  0.104011       NaN  0.850229\n",
      "4   5       NaN  1.057740  0.165562       NaN\n",
      "5   6 -1.336940  0.562861  1.392850 -0.063328\n",
      "6   7  0.121668  1.207600 -0.002040  1.627800\n",
      "7   8  0.354493  1.037530 -0.385684  0.519818\n",
      "8   9  1.686580 -1.325960  1.428980 -2.089350\n",
      "9  10 -0.129820  0.631523 -0.586538       NaN\n",
      "\n",
      "Background:black - fontcolor:yelow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a020e_row0_col0, #T_a020e_row0_col1, #T_a020e_row0_col2, #T_a020e_row0_col3, #T_a020e_row0_col4, #T_a020e_row1_col0, #T_a020e_row1_col1, #T_a020e_row1_col2, #T_a020e_row1_col3, #T_a020e_row1_col4, #T_a020e_row2_col0, #T_a020e_row2_col1, #T_a020e_row2_col2, #T_a020e_row2_col3, #T_a020e_row2_col4, #T_a020e_row3_col0, #T_a020e_row3_col1, #T_a020e_row3_col2, #T_a020e_row3_col3, #T_a020e_row3_col4, #T_a020e_row4_col0, #T_a020e_row4_col1, #T_a020e_row4_col2, #T_a020e_row4_col3, #T_a020e_row4_col4, #T_a020e_row5_col0, #T_a020e_row5_col1, #T_a020e_row5_col2, #T_a020e_row5_col3, #T_a020e_row5_col4, #T_a020e_row6_col0, #T_a020e_row6_col1, #T_a020e_row6_col2, #T_a020e_row6_col3, #T_a020e_row6_col4, #T_a020e_row7_col0, #T_a020e_row7_col1, #T_a020e_row7_col2, #T_a020e_row7_col3, #T_a020e_row7_col4, #T_a020e_row8_col0, #T_a020e_row8_col1, #T_a020e_row8_col2, #T_a020e_row8_col3, #T_a020e_row8_col4, #T_a020e_row9_col0, #T_a020e_row9_col1, #T_a020e_row9_col2, #T_a020e_row9_col3, #T_a020e_row9_col4 {\n",
       "  background-color: black;\n",
       "  color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a020e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a020e_level0_col0\" class=\"col_heading level0 col0\" >A</th>\n",
       "      <th id=\"T_a020e_level0_col1\" class=\"col_heading level0 col1\" >B</th>\n",
       "      <th id=\"T_a020e_level0_col2\" class=\"col_heading level0 col2\" >C</th>\n",
       "      <th id=\"T_a020e_level0_col3\" class=\"col_heading level0 col3\" >D</th>\n",
       "      <th id=\"T_a020e_level0_col4\" class=\"col_heading level0 col4\" >E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a020e_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_a020e_row0_col1\" class=\"data row0 col1\" >1.329210</td>\n",
       "      <td id=\"T_a020e_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_a020e_row0_col3\" class=\"data row0 col3\" >-0.316280</td>\n",
       "      <td id=\"T_a020e_row0_col4\" class=\"data row0 col4\" >-0.990810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a020e_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_a020e_row1_col1\" class=\"data row1 col1\" >-1.070820</td>\n",
       "      <td id=\"T_a020e_row1_col2\" class=\"data row1 col2\" >-1.438710</td>\n",
       "      <td id=\"T_a020e_row1_col3\" class=\"data row1 col3\" >0.564417</td>\n",
       "      <td id=\"T_a020e_row1_col4\" class=\"data row1 col4\" >0.295722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a020e_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_a020e_row2_col1\" class=\"data row2 col1\" >-1.626400</td>\n",
       "      <td id=\"T_a020e_row2_col2\" class=\"data row2 col2\" >0.219565</td>\n",
       "      <td id=\"T_a020e_row2_col3\" class=\"data row2 col3\" >0.678805</td>\n",
       "      <td id=\"T_a020e_row2_col4\" class=\"data row2 col4\" >1.889270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a020e_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_a020e_row3_col1\" class=\"data row3 col1\" >0.961538</td>\n",
       "      <td id=\"T_a020e_row3_col2\" class=\"data row3 col2\" >0.104011</td>\n",
       "      <td id=\"T_a020e_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_a020e_row3_col4\" class=\"data row3 col4\" >0.850229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a020e_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_a020e_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "      <td id=\"T_a020e_row4_col2\" class=\"data row4 col2\" >1.057740</td>\n",
       "      <td id=\"T_a020e_row4_col3\" class=\"data row4 col3\" >0.165562</td>\n",
       "      <td id=\"T_a020e_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a020e_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_a020e_row5_col1\" class=\"data row5 col1\" >-1.336940</td>\n",
       "      <td id=\"T_a020e_row5_col2\" class=\"data row5 col2\" >0.562861</td>\n",
       "      <td id=\"T_a020e_row5_col3\" class=\"data row5 col3\" >1.392850</td>\n",
       "      <td id=\"T_a020e_row5_col4\" class=\"data row5 col4\" >-0.063328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a020e_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_a020e_row6_col1\" class=\"data row6 col1\" >0.121668</td>\n",
       "      <td id=\"T_a020e_row6_col2\" class=\"data row6 col2\" >1.207600</td>\n",
       "      <td id=\"T_a020e_row6_col3\" class=\"data row6 col3\" >-0.002040</td>\n",
       "      <td id=\"T_a020e_row6_col4\" class=\"data row6 col4\" >1.627800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a020e_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_a020e_row7_col1\" class=\"data row7 col1\" >0.354493</td>\n",
       "      <td id=\"T_a020e_row7_col2\" class=\"data row7 col2\" >1.037530</td>\n",
       "      <td id=\"T_a020e_row7_col3\" class=\"data row7 col3\" >-0.385684</td>\n",
       "      <td id=\"T_a020e_row7_col4\" class=\"data row7 col4\" >0.519818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a020e_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_a020e_row8_col1\" class=\"data row8 col1\" >1.686580</td>\n",
       "      <td id=\"T_a020e_row8_col2\" class=\"data row8 col2\" >-1.325960</td>\n",
       "      <td id=\"T_a020e_row8_col3\" class=\"data row8 col3\" >1.428980</td>\n",
       "      <td id=\"T_a020e_row8_col4\" class=\"data row8 col4\" >-2.089350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a020e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a020e_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_a020e_row9_col1\" class=\"data row9 col1\" >-0.129820</td>\n",
       "      <td id=\"T_a020e_row9_col2\" class=\"data row9 col2\" >0.631523</td>\n",
       "      <td id=\"T_a020e_row9_col3\" class=\"data row9 col3\" >-0.586538</td>\n",
       "      <td id=\"T_a020e_row9_col4\" class=\"data row9 col4\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e1665e1510>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12\n",
    "print(\"Original array:\")\n",
    "print(df)\n",
    "print(\"\\nBackground:black - fontcolor:yelow\")\n",
    "df.style.set_properties(**{'background-color': 'black',\n",
    "'color': 'yellow'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f2b180b-9388-4680-b3fa-766e46edeb66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "     ord_no  purch_amt     ord_date  customer_id  salesman_id\n",
      "0   70001.0     150.50   2012-10-05         3002       5002.0\n",
      "1       NaN     270.65   2012-09-10         3001       5003.0\n",
      "2   70002.0      65.26          NaN         3001       5001.0\n",
      "3   70004.0     110.50   2012-08-17         3003          NaN\n",
      "4       NaN     948.50   2012-09-10         3002       5002.0\n",
      "5   70005.0    2400.60  2012-07- 27         3001       5001.0\n",
      "6       NaN    5760.00   2012-09-10         3001       5001.0\n",
      "7   70010.0    1983.43   2012-10-10         3004          NaN\n",
      "8   70003.0    2480.40   2012-10-10         3003       5003.0\n",
      "9   70012.0     250.45   2012-06-27         3002       5002.0\n",
      "10      NaN      75.29   2012-08-17         3001       5003.0\n",
      "11  70013.0    3045.60   2012-04-25         3001          NaN\n",
      "\n",
      "Missing values of the said dataframe:\n",
      "    ord_no  purch_amt  ord_date  customer_id  salesman_id\n",
      "0    False      False     False        False        False\n",
      "1     True      False     False        False        False\n",
      "2    False      False      True        False        False\n",
      "3    False      False     False        False         True\n",
      "4     True      False     False        False        False\n",
      "5    False      False     False        False        False\n",
      "6     True      False     False        False        False\n",
      "7    False      False     False        False         True\n",
      "8    False      False     False        False        False\n",
      "9    False      False     False        False        False\n",
      "10    True      False     False        False        False\n",
      "11   False      False     False        False         True\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan, 70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07- 27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nMissing values of the said dataframe:\")\n",
    "print(df.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7dc1330-7d31-48b1-97ec-1004ab91a0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "   ord_no purch_amt     ord_date customer_id salesman_id\n",
      "0   70001     150.5            ?        3002        5002\n",
      "1     NaN    270.65   2012-09-10        3001        5003\n",
      "2   70002     65.26          NaN        3001           ?\n",
      "3   70004     110.5   2012-08-17        3003        5001\n",
      "4     NaN     948.5   2012-09-10        3002         NaN\n",
      "5   70005    2400.6   2012-07-27        3001        5002\n",
      "6     --       5760  2012-09- 10        3001        5001\n",
      "7   70010         ?   2012-10-10        3004           ?\n",
      "8   70003     12.43   2012-10-10          --        5003\n",
      "9   70012    2480.4   2012-06-27        3002        5002\n",
      "10    NaN    250.45   2012-08-17        3001        5003\n",
      "11  70013    3045.6   2012-04-25        3001          --\n",
      "\n",
      "Replace the missing values with NaN:\n",
      "   ord_no  purch_amt     ord_date  customer_id  salesman_id\n",
      "0   70001     150.50          NaN       3002.0       5002.0\n",
      "1     NaN     270.65   2012-09-10       3001.0       5003.0\n",
      "2   70002      65.26          NaN       3001.0          NaN\n",
      "3   70004     110.50   2012-08-17       3003.0       5001.0\n",
      "4     NaN     948.50   2012-09-10       3002.0          NaN\n",
      "5   70005    2400.60   2012-07-27       3001.0       5002.0\n",
      "6     --     5760.00  2012-09- 10       3001.0       5001.0\n",
      "7   70010        NaN   2012-10-10       3004.0          NaN\n",
      "8   70003      12.43   2012-10-10          NaN       5003.0\n",
      "9   70012    2480.40   2012-06-27       3002.0       5002.0\n",
      "10    NaN     250.45   2012-08-17       3001.0       5003.0\n",
      "11  70013    3045.60   2012-04-25       3001.0          NaN\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,\"-- \",70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,\"?\",12.43,2480.4,250.45, 3045.6],\n",
    "'ord_date': ['?','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09- 10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,\"--\",3002,3001,3001],\n",
    "'salesman_id':[5002,5003,\"?\",5001,np.nan,5002,5001,\"?\",5003,5002,5003,\"--\"]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nReplace the missing values with NaN:\")\n",
    "result = df.replace({\"?\": np.nan, \"--\": np.nan})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4748d69-20fa-453d-9d60-ee0e57ccdfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "     ord_no  purch_amt     ord_date  customer_id\n",
      "0       NaN        NaN          NaN          NaN\n",
      "1       NaN     270.65   2012-09-10       3001.0\n",
      "2   70002.0      65.26          NaN       3001.0\n",
      "3       NaN        NaN          NaN          NaN\n",
      "4       NaN     948.50   2012-09-10       3002.0\n",
      "5   70005.0    2400.60   2012-07-27       3001.0\n",
      "6       NaN    5760.00  2012-09- 10       3001.0\n",
      "7   70010.0    1983.43   2012-10-10       3004.0\n",
      "8   70003.0    2480.40   2012-10-10       3003.0\n",
      "9   70012.0     250.45   2012-06-27       3002.0\n",
      "10      NaN      75.29   2012-08-17       3001.0\n",
      "11      NaN        NaN          NaN          NaN\n",
      "\n",
      "Keep the rows with at least 2 NaN values of the said DataFrame:\n",
      "     ord_no  purch_amt     ord_date  customer_id\n",
      "1       NaN     270.65   2012-09-10       3001.0\n",
      "2   70002.0      65.26          NaN       3001.0\n",
      "4       NaN     948.50   2012-09-10       3002.0\n",
      "5   70005.0    2400.60   2012-07-27       3001.0\n",
      "6       NaN    5760.00  2012-09- 10       3001.0\n",
      "7   70010.0    1983.43   2012-10-10       3004.0\n",
      "8   70003.0    2480.40   2012-10-10       3003.0\n",
      "9   70012.0     250.45   2012-06-27       3002.0\n",
      "10      NaN      75.29   2012-08-17       3001.0\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[np.nan,np.nan,70002,np.nan,np.nan,70005,np.nan,70010,70003,70012,np.nan,np.nan],\n",
    "'purch_amt':[np.nan,270.65,65.26,np.nan,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,np.nan],\n",
    "'ord_date': [np.nan,'2012-09-10',np.nan,np.nan,'2012-09-10','2012-07-27','2012-09- 10','2012-10-10','2012-10-10','2012-06-27','2012-08-17',np.nan],\n",
    "'customer_id':[np.nan,3001,3001,np.nan,3002,3001,3001,3004,3003,3002,3001,np.nan]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nKeep the rows with at least 2 NaN values of the said DataFrame:\")\n",
    "result = df.dropna(thresh=2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc82d879-db87-4071-b323-0b281cb6b5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "\n",
      "Group:\n",
      "('s001',)\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "\n",
      "Group:\n",
      "('s002',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "\n",
      "Group:\n",
      "('s003',)\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "\n",
      "Group:\n",
      "('s004',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill',\n",
    "'David Parkes'],\n",
    "'date_Of_Birth ':\n",
    "['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "'age': [12, 12, 13, 13, 14, 12],\n",
    "'height': [173, 192, 186, 167, 151, 159],\n",
    "'weight': [35, 32, 33, 30, 31, 32],\n",
    "'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']}, index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "result = student_data.groupby(['school_code'])\n",
    "for name,group in result:\n",
    "    print(\"\\nGroup:\")\n",
    "    print(name)\n",
    "    print(group)\n",
    "    print(\"\\nType of the object:\")\n",
    "    print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6792326-7274-4acd-b561-8aad177b18c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age   height   weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12       173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12       192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13       186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13       167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14       151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12       159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Mean, min, and max value of age for each school with customized column names:\n",
      "             Age_Mean  Age_Max  Age_Min\n",
      "school_code                            \n",
      "s001             12.5       13       12\n",
      "s002             13.0       14       12\n",
      "s003             13.0       13       13\n",
      "s004             12.0       12       12\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill',\n",
    "'David Parkes'],\n",
    "'date_Of_Birth ':\n",
    "['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "'age': [12, 12, 13, 13, 14, 12],\n",
    "' height ': [173, 192, 186, 167, 151, 159],\n",
    "'weight': [35, 32, 33, 30, 31, 32],\n",
    "'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']}, index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nMean, min, and max value of age for each school with customized column names:')\n",
    "grouped_single = student_data.groupby('school_code').agg(Age_Mean =\n",
    "('age','mean'),Age_Max=('age',max),Age_Min=('age',min))\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315cfdda-332c-4841-afc1-7c8172b122c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "\n",
      "Group:\n",
      "('s001',)\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "\n",
      "Group:\n",
      "('s002',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "\n",
      "Group:\n",
      "('s003',)\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "\n",
      "Group:\n",
      "('s004',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill',\n",
    "'David Parkes'],\n",
    "'date_Of_Birth ':\n",
    "['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "'age': [12, 12, 13, 13, 14, 12],\n",
    "'height': [173, 192, 186, 167, 151, 159],\n",
    "'weight': [35, 32, 33, 30, 31, 32],\n",
    "'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']}, index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "result = student_data.groupby(['school_code'])\n",
    "for name,group in result:\n",
    "    print(\"\\nGroup:\")\n",
    "    print(name)\n",
    "    print(group)\n",
    "    print(\"\\nType of the object:\")\n",
    "    print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123b595-4dc7-4af0-b51c-57f0d74513c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
